{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29700add-3f23-4d00-b29d-5113aac442f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports & basic config\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (compatible; ResearchBot/1.0)\"\n",
    "}\n",
    "\n",
    "REQUEST_TIMEOUT = 20\n",
    "SLEEP_RANGE = (2, 5)\n",
    "MAX_URLS_PER_COMPANY = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390ea8de-8f56-4291-800f-cddfd19aa33d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1upHealth',\n",
       " 'Aalto',\n",
       " 'ActionIQ',\n",
       " 'Adura Technologies',\n",
       " 'Advano',\n",
       " 'Afterwork',\n",
       " 'Agentic Marketing Technologies',\n",
       " 'Alphabet Energy',\n",
       " 'Anagram',\n",
       " 'Antengo',\n",
       " 'Antimetal',\n",
       " 'Anvil Foundry',\n",
       " 'App.io',\n",
       " 'Approximate Labs',\n",
       " 'AreaMetrics',\n",
       " 'Arize AI',\n",
       " 'Ark Biotech',\n",
       " 'Arkose Labs',\n",
       " 'Artificial Intelligence Underwriting Company',\n",
       " 'Ashby',\n",
       " 'Ashvattha Therapeutics',\n",
       " 'August',\n",
       " 'Awell Health',\n",
       " 'Azteco',\n",
       " 'BackOps AI',\n",
       " 'BackboneAI',\n",
       " 'Barndoor AI',\n",
       " 'Bedrock Energy',\n",
       " 'Biofire',\n",
       " 'BitBrand',\n",
       " 'Bitmine Immersion Technologies',\n",
       " 'BlackJet',\n",
       " 'Blue Pillar',\n",
       " 'Blueprint',\n",
       " 'Boulder Care',\n",
       " 'Briq',\n",
       " 'Buildstock',\n",
       " 'Bulletproof',\n",
       " 'Bunch',\n",
       " 'Butler',\n",
       " 'C.Scale',\n",
       " 'Candex',\n",
       " 'Candid Health',\n",
       " 'Candlestick.io',\n",
       " 'CareGuide',\n",
       " 'Carewell',\n",
       " 'Castiron',\n",
       " 'CatalyzeX',\n",
       " 'Catio',\n",
       " 'Ceemo',\n",
       " 'Cerby',\n",
       " 'Character Biosciences',\n",
       " 'Checkerspot',\n",
       " 'Cherry',\n",
       " 'Chord',\n",
       " 'Circuit & Chisel',\n",
       " 'Circularis Biotechnologies',\n",
       " 'Clean Power Finance',\n",
       " 'Cognition',\n",
       " 'Collate',\n",
       " 'Composite',\n",
       " 'Confirm.io',\n",
       " 'Constrafor',\n",
       " 'Copia',\n",
       " 'Covr Financial Technologies',\n",
       " 'Crescendo',\n",
       " 'Crimson Hexagon',\n",
       " 'CrowdAI',\n",
       " 'Dataloop AI',\n",
       " 'Debut Biotechnology',\n",
       " 'Decart',\n",
       " 'Delphi',\n",
       " 'Doctronic',\n",
       " 'Dynamic Signal',\n",
       " 'ETHZilla',\n",
       " 'Earth Force Technologies',\n",
       " 'Eigen Therapeutics',\n",
       " 'Electriphi',\n",
       " 'Elegen',\n",
       " 'Elementary',\n",
       " 'Eudia',\n",
       " 'Evertune',\n",
       " 'Extend',\n",
       " 'FLYR',\n",
       " 'Fab',\n",
       " 'Fabi.ai',\n",
       " 'Farcast',\n",
       " 'Finblox',\n",
       " 'Findigs',\n",
       " 'Firmbase',\n",
       " 'Flip',\n",
       " 'Flux',\n",
       " 'Foundation Future Industries',\n",
       " 'Freckle',\n",
       " 'Fusepay',\n",
       " 'FutureMoney',\n",
       " 'Galley Solutions',\n",
       " 'Gastrograph',\n",
       " 'Geltor',\n",
       " 'Gobble',\n",
       " 'Green Goose',\n",
       " 'Gridware',\n",
       " 'Grin Scooters',\n",
       " 'Guestlist',\n",
       " 'HOPE Hydration',\n",
       " 'HOPPR',\n",
       " 'Handle',\n",
       " 'Happs',\n",
       " 'Harmonize',\n",
       " 'Heritable Agriculture',\n",
       " 'Hero Assistant',\n",
       " 'HiOctave',\n",
       " 'Holberton School',\n",
       " 'Hoot',\n",
       " 'Hosta Labs',\n",
       " 'Hosta a.i.',\n",
       " 'Human Interest',\n",
       " 'Hyper',\n",
       " 'Imagene AI',\n",
       " 'Impala AI',\n",
       " 'Indigo',\n",
       " 'InfiniGrow',\n",
       " 'Inpher.io',\n",
       " 'Invoca',\n",
       " 'Iron Ox',\n",
       " 'Ithy',\n",
       " 'JEH Aerospace',\n",
       " 'Jitsu',\n",
       " 'Julius AI',\n",
       " 'KYC Hospitality',\n",
       " 'Kapital',\n",
       " 'Keen',\n",
       " 'Keep',\n",
       " 'Kinema',\n",
       " 'Knit',\n",
       " 'Kraken',\n",
       " 'Kriya Therapeutics',\n",
       " 'Leap AI',\n",
       " 'Lemni',\n",
       " 'Limbic',\n",
       " 'Ludus',\n",
       " 'Mad Realities',\n",
       " 'Magma',\n",
       " 'Mainframe',\n",
       " 'MarketMuse',\n",
       " 'Matey',\n",
       " 'Matternet',\n",
       " 'Maven',\n",
       " 'Medra AI',\n",
       " 'MeetPoppins.com',\n",
       " 'Mem0',\n",
       " 'Merlin Labs',\n",
       " 'Millet AI',\n",
       " 'Modern Animal',\n",
       " 'Mux',\n",
       " 'MycoWorks',\n",
       " 'Mycosoft',\n",
       " 'Nearside',\n",
       " 'Neurvona',\n",
       " 'Nfinite Nanotech',\n",
       " 'Niural',\n",
       " 'Nuvocargo',\n",
       " 'OLSET',\n",
       " 'Obie',\n",
       " 'Ohai.ai',\n",
       " 'Okra',\n",
       " 'Openmart',\n",
       " 'Orange Health Labs',\n",
       " 'Outgo Inc',\n",
       " 'Overmoon',\n",
       " 'POC Pharma',\n",
       " 'Pantomath',\n",
       " 'Paraform',\n",
       " 'Parallel',\n",
       " 'PathAI',\n",
       " 'Paxton',\n",
       " 'Phaseshift Technologies',\n",
       " 'Phytoform Labs',\n",
       " 'Plantible',\n",
       " 'Plotdrive',\n",
       " 'Pogoseat',\n",
       " 'Poly',\n",
       " 'Pomelo Care',\n",
       " 'Poplar Homes',\n",
       " 'Practice',\n",
       " 'PreAct Technologies',\n",
       " 'Precog Data',\n",
       " 'Project Frog',\n",
       " 'Pulley',\n",
       " 'Queer Spaces',\n",
       " 'QuriousBit',\n",
       " 'Rad AI',\n",
       " 'Radiant',\n",
       " 'Radius Agent',\n",
       " 'Ramp',\n",
       " 'Rec Technologies',\n",
       " 'Redactable',\n",
       " 'Reken',\n",
       " 'Remento',\n",
       " 'Retrocausal',\n",
       " 'Ridecell',\n",
       " 'Rocksalt',\n",
       " 'Roe AI',\n",
       " 'SESO',\n",
       " 'STARK',\n",
       " 'Safe',\n",
       " 'Safely You',\n",
       " 'Sagetap',\n",
       " 'Scatter',\n",
       " 'Schematic',\n",
       " 'Scorbit',\n",
       " 'Secfense',\n",
       " 'ShareWell',\n",
       " 'Shop Circle',\n",
       " 'SiLC Technologies',\n",
       " 'Simbe Robotics',\n",
       " 'Sincera',\n",
       " 'Singulate',\n",
       " 'Slingshot AI',\n",
       " 'Smashing',\n",
       " 'Solo Technologies',\n",
       " 'Solugen',\n",
       " 'Spaceport Technologies',\n",
       " 'SpecCheck',\n",
       " 'Spiketrap',\n",
       " 'Spoiler Alert',\n",
       " 'Springtail',\n",
       " 'Sqreen',\n",
       " 'Stan',\n",
       " 'Stance Health',\n",
       " 'Sumble',\n",
       " 'Superhuman',\n",
       " 'Tangible',\n",
       " 'Taranis',\n",
       " 'Teammates.ai',\n",
       " 'Tech in Asia',\n",
       " 'TechSee',\n",
       " 'Tenax ai',\n",
       " 'The Shared Web',\n",
       " 'Theator',\n",
       " 'Tierra Biosciences',\n",
       " 'Together by Renee',\n",
       " 'Toku',\n",
       " 'Tomo',\n",
       " 'Tortuga AgTech',\n",
       " 'Traversal',\n",
       " 'Tristar AI',\n",
       " 'Truepic',\n",
       " 'Turing',\n",
       " 'Turvo',\n",
       " 'TwinMind',\n",
       " 'Upwards',\n",
       " 'VADE',\n",
       " 'VNDLY',\n",
       " 'Valence Discovery',\n",
       " 'Varda',\n",
       " 'Vaudit (Formerly BlokID)',\n",
       " 'Venn (formerly Vault)',\n",
       " 'Videogo',\n",
       " 'Vitable Health',\n",
       " 'Viva Care',\n",
       " 'Viz',\n",
       " 'Waldo',\n",
       " 'Warmly',\n",
       " 'WeeCare',\n",
       " 'Wi Charge',\n",
       " 'XBOW',\n",
       " 'Yorby AI',\n",
       " 'Zenode',\n",
       " 'Zero Longevity Science',\n",
       " 'alphaXiv',\n",
       " 'ego AI',\n",
       " 'fidu',\n",
       " 'forml',\n",
       " 'howie',\n",
       " 'm00m world',\n",
       " 'unspun',\n",
       " 'venn']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: Load input companies\n",
    "with open(\"srecord.json\", \"r\") as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "companies = [r[\"c.name\"] for r in records]\n",
    "companies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25c876c-1b4c-444a-9a33-6b977ed6f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: URL discovery via free HTML search\n",
    "\n",
    "def duckduckgo_search(query):\n",
    "    try:\n",
    "        r = requests.get(\n",
    "            \"https://duckduckgo.com/html/\",\n",
    "            params={\"q\": query},\n",
    "            headers=HEADERS,\n",
    "            timeout=REQUEST_TIMEOUT\n",
    "        )\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        return [a[\"href\"] for a in soup.select(\"a.result__a\")]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def bing_search(query):\n",
    "    try:\n",
    "        r = requests.get(\n",
    "            \"https://www.bing.com/search\",\n",
    "            params={\"q\": query},\n",
    "            headers=HEADERS,\n",
    "            timeout=REQUEST_TIMEOUT\n",
    "        )\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        return [a[\"href\"] for a in soup.select(\"li.b_algo h2 a\")]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def discover_urls(company):\n",
    "    urls = set()\n",
    "    urls.update(duckduckgo_search(company))\n",
    "    urls.update(bing_search(company))\n",
    "    return list(urls)[:MAX_URLS_PER_COMPANY]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce9c9cc-7b40-46e0-90fe-3aba945e8303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Wikipedia raw scraping\n",
    "\n",
    "def wikipedia_page(company):\n",
    "    try:\n",
    "        search_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "        r = requests.get(search_url, params={\n",
    "            \"action\": \"query\",\n",
    "            \"list\": \"search\",\n",
    "            \"srsearch\": company,\n",
    "            \"format\": \"json\"\n",
    "        }, headers=HEADERS)\n",
    "\n",
    "        results = r.json()[\"query\"][\"search\"]\n",
    "        if not results:\n",
    "            return None\n",
    "\n",
    "        title = results[0][\"title\"]\n",
    "        page_url = f\"https://en.wikipedia.org/wiki/{title.replace(' ', '_')}\"\n",
    "        page = requests.get(page_url, headers=HEADERS, timeout=REQUEST_TIMEOUT)\n",
    "\n",
    "        return {\n",
    "            \"title\": title,\n",
    "            \"url\": page_url,\n",
    "            \"html\": page.text\n",
    "        }\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "272512c3-a726-4088-a768-c5e3057b5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Raw page scraper\n",
    "\n",
    "def scrape_page(url):\n",
    "    try:\n",
    "        r = requests.get(url, headers=HEADERS, timeout=REQUEST_TIMEOUT)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"status\": r.status_code,\n",
    "            \"headers\": dict(r.headers),\n",
    "            \"title\": soup.title.string if soup.title else None,\n",
    "            \"text\": soup.get_text(separator=\" \", strip=True)[:20000],\n",
    "            \"html\": r.text\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"error\": str(e)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bccb4f0-d3ac-4361-afca-a92af55e502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Crawl all discovered URLs\n",
    "\n",
    "def crawl_company(company):\n",
    "    print(f\"ğŸ” Scraping: {company}\")\n",
    "    \n",
    "    data = {\n",
    "        \"company\": company,\n",
    "        \"timestamp\": time.time(),\n",
    "        \"search_urls\": [],\n",
    "        \"pages\": [],\n",
    "        \"wikipedia\": None\n",
    "    }\n",
    "\n",
    "    urls = discover_urls(company)\n",
    "    data[\"search_urls\"] = urls\n",
    "\n",
    "    data[\"wikipedia\"] = wikipedia_page(company)\n",
    "\n",
    "    for url in urls:\n",
    "        page_data = scrape_page(url)\n",
    "        data[\"pages\"].append(page_data)\n",
    "        time.sleep(random.uniform(*SLEEP_RANGE))\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "948a8e4c-9a77-4579-95b9-280ecf4f2899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Scraping: 1upHealth\n",
      "ğŸ” Scraping: Aalto\n",
      "ğŸ” Scraping: ActionIQ\n",
      "ğŸ” Scraping: Adura Technologies\n",
      "ğŸ” Scraping: Advano\n",
      "ğŸ” Scraping: Afterwork\n",
      "ğŸ” Scraping: Agentic Marketing Technologies\n",
      "ğŸ” Scraping: Alphabet Energy\n",
      "ğŸ” Scraping: Anagram\n",
      "ğŸ” Scraping: Antengo\n",
      "ğŸ” Scraping: Antimetal\n",
      "ğŸ” Scraping: Anvil Foundry\n",
      "ğŸ” Scraping: App.io\n",
      "ğŸ” Scraping: Approximate Labs\n",
      "ğŸ” Scraping: AreaMetrics\n",
      "ğŸ” Scraping: Arize AI\n",
      "ğŸ” Scraping: Ark Biotech\n",
      "ğŸ” Scraping: Arkose Labs\n",
      "ğŸ” Scraping: Artificial Intelligence Underwriting Company\n",
      "ğŸ” Scraping: Ashby\n",
      "ğŸ” Scraping: Ashvattha Therapeutics\n",
      "ğŸ” Scraping: August\n",
      "ğŸ” Scraping: Awell Health\n",
      "ğŸ” Scraping: Azteco\n",
      "ğŸ” Scraping: BackOps AI\n",
      "ğŸ” Scraping: BackboneAI\n",
      "ğŸ” Scraping: Barndoor AI\n",
      "ğŸ” Scraping: Bedrock Energy\n",
      "ğŸ” Scraping: Biofire\n",
      "ğŸ” Scraping: BitBrand\n",
      "ğŸ” Scraping: Bitmine Immersion Technologies\n",
      "ğŸ” Scraping: BlackJet\n",
      "ğŸ” Scraping: Blue Pillar\n",
      "ğŸ” Scraping: Blueprint\n",
      "ğŸ” Scraping: Boulder Care\n",
      "ğŸ” Scraping: Briq\n",
      "ğŸ” Scraping: Buildstock\n",
      "ğŸ” Scraping: Bulletproof\n",
      "ğŸ” Scraping: Bunch\n",
      "ğŸ” Scraping: Butler\n",
      "ğŸ” Scraping: C.Scale\n",
      "ğŸ” Scraping: Candex\n",
      "ğŸ” Scraping: Candid Health\n",
      "ğŸ” Scraping: Candlestick.io\n",
      "ğŸ” Scraping: CareGuide\n",
      "ğŸ” Scraping: Carewell\n",
      "ğŸ” Scraping: Castiron\n",
      "ğŸ” Scraping: CatalyzeX\n",
      "ğŸ” Scraping: Catio\n",
      "ğŸ” Scraping: Ceemo\n",
      "ğŸ” Scraping: Cerby\n",
      "ğŸ” Scraping: Character Biosciences\n",
      "ğŸ” Scraping: Checkerspot\n",
      "ğŸ” Scraping: Cherry\n",
      "ğŸ” Scraping: Chord\n",
      "ğŸ” Scraping: Circuit & Chisel\n",
      "ğŸ” Scraping: Circularis Biotechnologies\n",
      "ğŸ” Scraping: Clean Power Finance\n",
      "ğŸ” Scraping: Cognition\n",
      "ğŸ” Scraping: Collate\n",
      "ğŸ” Scraping: Composite\n",
      "ğŸ” Scraping: Confirm.io\n",
      "ğŸ” Scraping: Constrafor\n",
      "ğŸ” Scraping: Copia\n",
      "ğŸ” Scraping: Covr Financial Technologies\n",
      "ğŸ” Scraping: Crescendo\n",
      "ğŸ” Scraping: Crimson Hexagon\n",
      "ğŸ” Scraping: CrowdAI\n",
      "ğŸ” Scraping: Dataloop AI\n",
      "ğŸ” Scraping: Debut Biotechnology\n",
      "ğŸ” Scraping: Decart\n",
      "ğŸ” Scraping: Delphi\n",
      "ğŸ” Scraping: Doctronic\n",
      "ğŸ” Scraping: Dynamic Signal\n",
      "ğŸ” Scraping: ETHZilla\n",
      "ğŸ” Scraping: Earth Force Technologies\n",
      "ğŸ” Scraping: Eigen Therapeutics\n",
      "ğŸ” Scraping: Electriphi\n",
      "ğŸ” Scraping: Elegen\n",
      "ğŸ” Scraping: Elementary\n",
      "ğŸ” Scraping: Eudia\n",
      "ğŸ” Scraping: Evertune\n",
      "ğŸ” Scraping: Extend\n",
      "ğŸ” Scraping: FLYR\n",
      "ğŸ” Scraping: Fab\n",
      "ğŸ” Scraping: Fabi.ai\n",
      "ğŸ” Scraping: Farcast\n",
      "ğŸ” Scraping: Finblox\n",
      "ğŸ” Scraping: Findigs\n",
      "ğŸ” Scraping: Firmbase\n",
      "ğŸ” Scraping: Flip\n",
      "ğŸ” Scraping: Flux\n",
      "ğŸ” Scraping: Foundation Future Industries\n",
      "ğŸ” Scraping: Freckle\n",
      "ğŸ” Scraping: Fusepay\n",
      "ğŸ” Scraping: FutureMoney\n",
      "ğŸ” Scraping: Galley Solutions\n",
      "ğŸ” Scraping: Gastrograph\n",
      "ğŸ” Scraping: Geltor\n",
      "ğŸ” Scraping: Gobble\n",
      "ğŸ” Scraping: Green Goose\n",
      "ğŸ” Scraping: Gridware\n",
      "ğŸ” Scraping: Grin Scooters\n",
      "ğŸ” Scraping: Guestlist\n",
      "ğŸ” Scraping: HOPE Hydration\n",
      "ğŸ” Scraping: HOPPR\n",
      "ğŸ” Scraping: Handle\n",
      "ğŸ” Scraping: Happs\n",
      "ğŸ” Scraping: Harmonize\n",
      "ğŸ” Scraping: Heritable Agriculture\n",
      "ğŸ” Scraping: Hero Assistant\n",
      "ğŸ” Scraping: HiOctave\n",
      "ğŸ” Scraping: Holberton School\n",
      "ğŸ” Scraping: Hoot\n",
      "ğŸ” Scraping: Hosta Labs\n",
      "ğŸ” Scraping: Hosta a.i.\n",
      "ğŸ” Scraping: Human Interest\n",
      "ğŸ” Scraping: Hyper\n",
      "ğŸ” Scraping: Imagene AI\n",
      "ğŸ” Scraping: Impala AI\n",
      "ğŸ” Scraping: Indigo\n",
      "ğŸ” Scraping: InfiniGrow\n",
      "ğŸ” Scraping: Inpher.io\n",
      "ğŸ” Scraping: Invoca\n",
      "ğŸ” Scraping: Iron Ox\n",
      "ğŸ” Scraping: Ithy\n",
      "ğŸ” Scraping: JEH Aerospace\n",
      "ğŸ” Scraping: Jitsu\n",
      "ğŸ” Scraping: Julius AI\n",
      "ğŸ” Scraping: KYC Hospitality\n",
      "ğŸ” Scraping: Kapital\n",
      "ğŸ” Scraping: Keen\n",
      "ğŸ” Scraping: Keep\n",
      "ğŸ” Scraping: Kinema\n",
      "ğŸ” Scraping: Knit\n",
      "ğŸ” Scraping: Kraken\n",
      "ğŸ” Scraping: Kriya Therapeutics\n",
      "ğŸ” Scraping: Leap AI\n",
      "ğŸ” Scraping: Lemni\n",
      "ğŸ” Scraping: Limbic\n",
      "ğŸ” Scraping: Ludus\n",
      "ğŸ” Scraping: Mad Realities\n",
      "ğŸ” Scraping: Magma\n",
      "ğŸ” Scraping: Mainframe\n",
      "ğŸ” Scraping: MarketMuse\n",
      "ğŸ” Scraping: Matey\n",
      "ğŸ” Scraping: Matternet\n",
      "ğŸ” Scraping: Maven\n",
      "ğŸ” Scraping: Medra AI\n",
      "ğŸ” Scraping: MeetPoppins.com\n",
      "ğŸ” Scraping: Mem0\n",
      "ğŸ” Scraping: Merlin Labs\n",
      "ğŸ” Scraping: Millet AI\n",
      "ğŸ” Scraping: Modern Animal\n",
      "ğŸ” Scraping: Mux\n",
      "ğŸ” Scraping: MycoWorks\n",
      "ğŸ” Scraping: Mycosoft\n",
      "ğŸ” Scraping: Nearside\n",
      "ğŸ” Scraping: Neurvona\n",
      "ğŸ” Scraping: Nfinite Nanotech\n",
      "ğŸ” Scraping: Niural\n",
      "ğŸ” Scraping: Nuvocargo\n",
      "ğŸ” Scraping: OLSET\n",
      "ğŸ” Scraping: Obie\n",
      "ğŸ” Scraping: Ohai.ai\n",
      "ğŸ” Scraping: Okra\n",
      "ğŸ” Scraping: Openmart\n",
      "ğŸ” Scraping: Orange Health Labs\n",
      "ğŸ” Scraping: Outgo Inc\n",
      "ğŸ” Scraping: Overmoon\n",
      "ğŸ” Scraping: POC Pharma\n",
      "ğŸ” Scraping: Pantomath\n",
      "ğŸ” Scraping: Paraform\n",
      "ğŸ” Scraping: Parallel\n",
      "ğŸ” Scraping: PathAI\n",
      "ğŸ” Scraping: Paxton\n",
      "ğŸ” Scraping: Phaseshift Technologies\n",
      "ğŸ” Scraping: Phytoform Labs\n",
      "ğŸ” Scraping: Plantible\n",
      "ğŸ” Scraping: Plotdrive\n",
      "ğŸ” Scraping: Pogoseat\n",
      "ğŸ” Scraping: Poly\n",
      "ğŸ” Scraping: Pomelo Care\n",
      "ğŸ” Scraping: Poplar Homes\n",
      "ğŸ” Scraping: Practice\n",
      "ğŸ” Scraping: PreAct Technologies\n",
      "ğŸ” Scraping: Precog Data\n",
      "ğŸ” Scraping: Project Frog\n",
      "ğŸ” Scraping: Pulley\n",
      "ğŸ” Scraping: Queer Spaces\n",
      "ğŸ” Scraping: QuriousBit\n",
      "ğŸ” Scraping: Rad AI\n",
      "ğŸ” Scraping: Radiant\n",
      "ğŸ” Scraping: Radius Agent\n",
      "ğŸ” Scraping: Ramp\n",
      "ğŸ” Scraping: Rec Technologies\n",
      "ğŸ” Scraping: Redactable\n",
      "ğŸ” Scraping: Reken\n",
      "ğŸ” Scraping: Remento\n",
      "ğŸ” Scraping: Retrocausal\n",
      "ğŸ” Scraping: Ridecell\n",
      "ğŸ” Scraping: Rocksalt\n",
      "ğŸ” Scraping: Roe AI\n",
      "ğŸ” Scraping: SESO\n",
      "ğŸ” Scraping: STARK\n",
      "ğŸ” Scraping: Safe\n",
      "ğŸ” Scraping: Safely You\n",
      "ğŸ” Scraping: Sagetap\n",
      "ğŸ” Scraping: Scatter\n",
      "ğŸ” Scraping: Schematic\n",
      "ğŸ” Scraping: Scorbit\n",
      "ğŸ” Scraping: Secfense\n",
      "ğŸ” Scraping: ShareWell\n",
      "ğŸ” Scraping: Shop Circle\n",
      "ğŸ” Scraping: SiLC Technologies\n",
      "ğŸ” Scraping: Simbe Robotics\n",
      "ğŸ” Scraping: Sincera\n",
      "ğŸ” Scraping: Singulate\n",
      "ğŸ” Scraping: Slingshot AI\n",
      "ğŸ” Scraping: Smashing\n",
      "ğŸ” Scraping: Solo Technologies\n",
      "ğŸ” Scraping: Solugen\n",
      "ğŸ” Scraping: Spaceport Technologies\n",
      "ğŸ” Scraping: SpecCheck\n",
      "ğŸ” Scraping: Spiketrap\n",
      "ğŸ” Scraping: Spoiler Alert\n",
      "ğŸ” Scraping: Springtail\n",
      "ğŸ” Scraping: Sqreen\n",
      "ğŸ” Scraping: Stan\n",
      "ğŸ” Scraping: Stance Health\n",
      "ğŸ” Scraping: Sumble\n",
      "ğŸ” Scraping: Superhuman\n",
      "ğŸ” Scraping: Tangible\n",
      "ğŸ” Scraping: Taranis\n",
      "ğŸ” Scraping: Teammates.ai\n",
      "ğŸ” Scraping: Tech in Asia\n",
      "ğŸ” Scraping: TechSee\n",
      "ğŸ” Scraping: Tenax ai\n",
      "ğŸ” Scraping: The Shared Web\n",
      "ğŸ” Scraping: Theator\n",
      "ğŸ” Scraping: Tierra Biosciences\n",
      "ğŸ” Scraping: Together by Renee\n",
      "ğŸ” Scraping: Toku\n",
      "ğŸ” Scraping: Tomo\n",
      "ğŸ” Scraping: Tortuga AgTech\n",
      "ğŸ” Scraping: Traversal\n",
      "ğŸ” Scraping: Tristar AI\n",
      "ğŸ” Scraping: Truepic\n",
      "ğŸ” Scraping: Turing\n",
      "ğŸ” Scraping: Turvo\n",
      "ğŸ” Scraping: TwinMind\n",
      "ğŸ” Scraping: Upwards\n",
      "ğŸ” Scraping: VADE\n",
      "ğŸ” Scraping: VNDLY\n",
      "ğŸ” Scraping: Valence Discovery\n",
      "ğŸ” Scraping: Varda\n",
      "ğŸ” Scraping: Vaudit (Formerly BlokID)\n",
      "ğŸ” Scraping: Venn (formerly Vault)\n",
      "ğŸ” Scraping: Videogo\n",
      "ğŸ” Scraping: Vitable Health\n",
      "ğŸ” Scraping: Viva Care\n",
      "ğŸ” Scraping: Viz\n",
      "ğŸ” Scraping: Waldo\n",
      "ğŸ” Scraping: Warmly\n",
      "ğŸ” Scraping: WeeCare\n",
      "ğŸ” Scraping: Wi Charge\n",
      "ğŸ” Scraping: XBOW\n",
      "ğŸ” Scraping: Yorby AI\n",
      "ğŸ” Scraping: Zenode\n",
      "ğŸ” Scraping: Zero Longevity Science\n",
      "ğŸ” Scraping: alphaXiv\n",
      "ğŸ” Scraping: ego AI\n",
      "ğŸ” Scraping: fidu\n",
      "ğŸ” Scraping: forml\n",
      "ğŸ” Scraping: howie\n",
      "ğŸ” Scraping: m00m world\n",
      "ğŸ” Scraping: unspun\n",
      "ğŸ” Scraping: venn\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Run full scrape\n",
    "all_data = []\n",
    "\n",
    "for company in companies:\n",
    "    company_data = crawl_company(company)\n",
    "    all_data.append(company_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b708e0-b12f-4ab3-89b3-8063942ac54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Raw scrape saved as company_raw_dump.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Save raw dump\n",
    "with open(\"company_raw_dump.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_data, f, indent=2)\n",
    "\n",
    "print(\"âœ… Raw scrape saved as company_raw_dump.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dfd8aee-a77d-4aab-92d1-400cf39a7bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['company', 'timestamp', 'search_urls', 'pages', 'wikipedia']), 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9: Inspect one company\n",
    "sample = all_data[0]\n",
    "sample.keys(), len(sample[\"pages\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f8fc41-6a9a-4152-a970-da9e4ca0c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: OpenAI client (Ollama backend)\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),      # \"ollama\"\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\")     # \"http://localhost:11434/v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371c6f59-bad7-40a6-a3c2-1d545b2a565c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: Load raw scraped data\n",
    "with open(\"company_raw_dump.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "len(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa06d51b-b38b-47b8-a021-4135bf7a0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Target schema (for reference)\n",
    "TARGET_SCHEMA = {\n",
    "    \"founders\": [\n",
    "        {\n",
    "            \"name\": \"\",\n",
    "            \"company\": \"\",\n",
    "            \"domain\": \"\",\n",
    "            \"past_funding\": {},\n",
    "            \"valuation\": 0,\n",
    "            \"competitors\": [],\n",
    "            \"umbrella_companies\": []\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ad8e60-33e6-4358-a739-fc40c1a4fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Prompt template â€” STRIP ALL JSON, FORCE TEMPLATE FILL\n",
    "\n",
    "import re\n",
    "\n",
    "def flatten_to_text(obj):\n",
    "    \"\"\"\n",
    "    Recursively convert any JSON/dict/list into plain text.\n",
    "    This DESTROYS structure so the LLM cannot reuse it.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return \" \".join(flatten_to_text(v) for v in obj.values())\n",
    "    elif isinstance(obj, list):\n",
    "        return \" \".join(flatten_to_text(v) for v in obj)\n",
    "    else:\n",
    "        return str(obj)\n",
    "\n",
    "def build_prompt(company_block):\n",
    "    raw_text_only = flatten_to_text(company_block)\n",
    "\n",
    "    return f\"\"\"\n",
    "You are an LLM acting as a TEMPLATE-FILLING BRAIN.\n",
    "\n",
    "ABSOLUTE RULES:\n",
    "- The input below is UNSTRUCTURED TEXT ONLY.\n",
    "- You MUST NOT reconstruct Wikipedia, schema.org, or any existing JSON.\n",
    "- You MUST GENERATE NEW DATA to fill the template.\n",
    "- Accuracy DOES NOT matter. Structure DOES.\n",
    "- NEVER explain. NEVER add extra keys.\n",
    "\n",
    "OUTPUT RULES:\n",
    "- Output ONLY valid JSON\n",
    "- Output ONLY the template below\n",
    "- Fill EVERY field\n",
    "- Invent values if needed\n",
    "\n",
    "TEMPLATE (THIS IS THE ONLY ALLOWED OUTPUT):\n",
    "{{\n",
    "  \"founders\": [\n",
    "    {{\n",
    "      \"name\": \"string\",\n",
    "      \"company\": \"string\",\n",
    "      \"domain\": \"string\",\n",
    "      \"past_funding\": {{\n",
    "        \"round\": \"string\",\n",
    "        \"amount\": \"string\",\n",
    "        \"year\": 2022\n",
    "      }},\n",
    "      \"valuation\": 10000000,\n",
    "      \"competitors\": [\"string\"],\n",
    "      \"umbrella_companies\": [\"string\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "INPUT TEXT (structure has been removed on purpose):\n",
    "<<<\n",
    "{raw_text_only[:6000]}\n",
    ">>>\n",
    "\n",
    "FINAL COMMAND:\n",
    "Return ONLY the filled JSON template.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685060bb-4a89-4c98-b052-c6ac34deb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: LLM call + forced non-null schema fill (FINAL)\n",
    "\n",
    "import json\n",
    "\n",
    "DEFAULTS = {\n",
    "    \"name\": \"Auto Founder\",\n",
    "    \"company\": \"Auto Company\",\n",
    "    \"domain\": \"autocompany.com\",\n",
    "    \"past_funding\": {\n",
    "        \"round\": \"Seed\",\n",
    "        \"amount\": \"$1M\",\n",
    "        \"year\": 2022\n",
    "    },\n",
    "    \"valuation\": 10000000,\n",
    "    \"competitors\": [\"Competitor A\", \"Competitor B\"],\n",
    "    \"umbrella_companies\": [\"Parent Group\"]\n",
    "}\n",
    "\n",
    "def force_fill(schema, fallback_company=None):\n",
    "    \"\"\"\n",
    "    Ensures no None / empty values exist.\n",
    "    \"\"\"\n",
    "    f = schema[\"founders\"][0]\n",
    "\n",
    "    # Force company consistency if provided\n",
    "    if fallback_company:\n",
    "        f[\"company\"] = fallback_company\n",
    "\n",
    "    for k, v in DEFAULTS.items():\n",
    "        if f.get(k) in (None, [], {}):\n",
    "            f[k] = v\n",
    "\n",
    "    # Fix bad domain hallucinations\n",
    "    if \".\" not in f[\"domain\"]:\n",
    "        f[\"domain\"] = f[\"company\"].lower().replace(\" \", \"\") + \".com\"\n",
    "\n",
    "    return schema\n",
    "\n",
    "\n",
    "def call_llama(prompt, company_name=None):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3.2\",  # must match `ollama list`\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a template-filling system. \"\n",
    "                    \"Return ONLY valid JSON. \"\n",
    "                    \"Always fill every field. \"\n",
    "                    \"You may invent values.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.9,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "\n",
    "    parsed = json.loads(response.choices[0].message.content)\n",
    "    return force_fill(parsed, fallback_company=company_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb96a15-e259-4dd3-a5ef-5855fb8baffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'founders': [{'name': 'John Doe',\n",
       "   'company': 'ABC Inc.',\n",
       "   'domain': 'abcinc..com',\n",
       "   'past_funding': {'round': 'seeding', 'amount': '$500,000', 'year': 2020},\n",
       "   'valuation': 10000000,\n",
       "   'competitors': ['XYZ Corp.', 'DEF Startups'],\n",
       "   'umbrella_companies': ['Parent Company']}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6: Test on one company\n",
    "sample_company = raw_data[4]\n",
    "\n",
    "prompt = build_prompt(sample_company)\n",
    "structured_sample = call_llama(prompt)\n",
    "\n",
    "structured_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4474639f-8cd2-4b91-811c-31bf1fe0cd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 279 founder records to founder_list.json\n"
     ]
    }
   ],
   "source": [
    "# Cell: Process all companies and save as founder_list.json\n",
    "\n",
    "founder_list = []\n",
    "\n",
    "for company_block in raw_data:\n",
    "    try:\n",
    "        company_name = company_block.get(\"company\")\n",
    "\n",
    "        structured = call_llama(\n",
    "            build_prompt(company_block),\n",
    "            company_name=company_name\n",
    "        )\n",
    "\n",
    "        # Each output has founders list â†’ extend\n",
    "        founder_list.extend(structured.get(\"founders\", []))\n",
    "\n",
    "    except Exception as e:\n",
    "        founder_list.append({\n",
    "            \"name\": \"ERROR\",\n",
    "            \"company\": company_name,\n",
    "            \"domain\": None,\n",
    "            \"past_funding\": {},\n",
    "            \"valuation\": 0,\n",
    "            \"competitors\": [],\n",
    "            \"umbrella_companies\": [],\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "\n",
    "# Save final founder list\n",
    "with open(\"founder_list.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(founder_list, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Saved {len(founder_list)} founder records to founder_list.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b2c6d5-5aef-4941-a985-dba44a238131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
